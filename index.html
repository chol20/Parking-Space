<html>
   <head>
      <meta content="text/html; charset=UTF-8" http-equiv="content-type">
      <style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c15{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:justify;height:11pt}.c22{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:justify}.c2{padding-top:0pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:justify;height:11pt}.c1{padding-top:20pt;padding-bottom:6pt;line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:justify}.c12{padding-top:0pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:center}.c11{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c7{padding-top:0pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:justify}.c5{color:#000000;text-decoration:none;vertical-align:baseline;font-size:11pt;font-style:normal}.c4{color:#000000;text-decoration:none;vertical-align:baseline;font-size:13pt;font-style:normal}.c6{color:#000000;text-decoration:none;vertical-align:baseline;font-style:normal}.c20{-webkit-text-decoration-skip:none;color:#681da8;text-decoration:underline;text-decoration-skip-ink:none}.c3{font-weight:400;font-family:"Times New Roman"}.c8{background-color:#ffffff;color:#222222}.c9{font-weight:700;font-family:"Times New Roman"}.c18{color:inherit;text-decoration:inherit}.c14{max-width:468pt;padding:72pt 72pt 72pt 72pt}.c23{font-style:italic}.c16{font-size:19pt}.c0{font-size:12pt}.c17{font-weight:700}.c13{background-color:#ffffff}.c21{height:11pt}.c10{font-size:16pt}.c19{font-size:20pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Times New Roman";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:justify}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:justify}li{color:#000000;font-size:11pt;font-family:"Times New Roman"}p{margin:0;color:#000000;font-size:11pt;font-family:"Times New Roman"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Times New Roman";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:justify}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Times New Roman";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:justify}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Times New Roman";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:justify}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Times New Roman";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:justify}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Times New Roman";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:justify}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Times New Roman";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:justify}</style>
   </head>
   <body class="c13 c14 doc-content">
      <p class="c12"><span class="c6 c9 c10">University of Juba</span></p>
      <p class="c12"><span class="c4 c9">PARKING SPACE OCCUPANCY</span></p>
      <p class="c12"><span class="c4 c9">Chol Abraham Akech</span></p>
      <p class="c2"><span class="c5 c3"></span></p>
      <h1 class="c1" id="h.jkw907t5q394"><span class="c6 c9 c19">Abstract</span></h1>
      <p class="c7"><span class="c3 c0">Parking guidance systems have recently become a popular trend as a part of the</span><span class="c0">&nbsp;</span><span class="c0 c3">smart cities&rsquo; paradigm of development. The crucial part of such systems is the</span><span class="c0">&nbsp;</span><span class="c3 c0">algorithm allowing drivers to search for available parking lots across regions of</span><span class="c0">&nbsp;</span><span class="c3 c0">interest. The classic approach to this task is based on the application of computer vision classifiers to</span><span class="c0">&nbsp;</span><span class="c3 c0">camera records. However, existing systems demonstrate a</span><span class="c0">&nbsp;</span><span class="c3 c0">lack of generalization ability and appropriate testing regarding specific visual</span><span class="c0">&nbsp;</span><span class="c3 c0">conditions. In this study, I extensively evaluate state-of-the-art parking space</span><span class="c0">&nbsp;</span><span class="c3 c0">occupancy detection algorithms, compare their prediction quality with the</span><span class="c0">&nbsp;</span><span class="c3 c0">recently emerged YOLO</span><span class="c0">&nbsp;</span><span class="c3 c0">version 8, and propose a new pipeline based on</span><span class="c0">&nbsp;</span><span class="c3 c0">Efficience, accuracy and speed. Performed computational experiments have</span><span class="c0">&nbsp;</span><span class="c3 c0">demonstrated the performance increase in the case of our model, which was</span><span class="c0">&nbsp;</span><span class="c3 c0">evaluated on ACMPS datasets.</span></p>
      <p class="c2"><span class="c6 c3 c0"></span></p>
      <p class="c7"><span class="c0 c17">Keywords:</span><span class="c0">&nbsp;computer vision; machine learning; deep learning; classification; object detection; parking space occupancy detection; smart city</span></p>
      <h1 class="c22" id="h.bn7m1r1r9mie"><span class="c6 c9 c16">Method Overview.</span></h1>
      <p class="c15"><span class="c5 c3"></span></p>
      <p class="c11"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 392.75px; height: 236.10px;"><img alt="" src="image1.png" style="width: 392.75px; height: 236.10px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p>
      <p class="c11 c21"><span class="c3 c5"></span></p>
      <h1 class="c1" id="h.6jd0ds7b7h8r"><span class="c4 c9">Dataset</span></h1>
      <p class="c7"><span class="c3 c0">I introduce a new dataset for parking space occupancy</span><span class="c0">&nbsp;</span><span class="c3 c0">classification: Action-Camera</span><span class="c0">&nbsp;</span><span class="c3 c0">Parking Dataset (ACPDS).</span><span class="c0">&nbsp;</span><span class="c6 c3 c0">The goal of my dataset is to improve and correctly test for</span></p>
      <p class="c7"><span class="c3 c0">model performance on previously unseen parking lots. To</span><span class="c0">&nbsp;</span><span class="c3 c0">this end, the dataset captures various parking lots, each image is captured from a unique view, systematically anno</span><span class="c3 c0">tated</span><span class="c3 c0">, and unique parking lots are used for the train, validation, and test sets. As a result, the validation and test</span><span class="c0">&nbsp;</span><span class="c6 c3 c0">accuracy obtained on our dataset correspond to model performance on a previously unseen parking lot.</span></p>
      <p class="c2"><span class="c4 c3"></span></p>
      <p class="c7"><span class="c4 c9">Data collection</span></p>
      <p class="c7"><span class="c3 c0">We mounted a GoPro Hero 6 action camera to a 12-meter</span><span class="c0">&nbsp;</span><span class="c3 c0">telescoping pole and used a smartphone to view a live feed</span><span class="c0">&nbsp;</span><span class="c3 c0">from the camera and control the shutter. This enabled us to</span><span class="c0">&nbsp;</span><span class="c3 c0">walk around with the setup and capture each image from a</span><span class="c0">&nbsp;</span><span class="c3 c0">unique view. We captured tens of different parking lots and</span><span class="c0">&nbsp;</span><span class="c3 c0">streets, under various weather and lighting conditions (see</span><span class="c0">&nbsp;</span><span class="c3 c0">Figure 2). However, we notably didn&rsquo;t capture any images</span><span class="c0">&nbsp;that</span><span class="c3 c0">&nbsp;</span><span class="c0">included</span><span class="c3 c0">&nbsp;snow.</span><span class="c0">&nbsp;</span><span class="c3 c0">Each image is captured by the same camera in the &ldquo;wide&rdquo;</span><span class="c0">&nbsp;</span><span class="c3 c0">field of view setting, in full (4000 x 3000) resolution.</span><span class="c0">&nbsp;</span><span class="c6 c3 c0">Moreover, each image is captured from a roughly 12-meter</span></p>
      <p class="c7"><span class="c3 c0">height, corresponding to a common height of lamp posts.</span><span class="c0">&nbsp;</span><span class="c3 c0">We consider this similarity to be crucial for practical appli-cations. If a camera were installed on a lamppost, it could</span><span class="c0">&nbsp;</span><span class="c3 c0">typically be at most 12 meters above the ground, resulting in</span><span class="c0">&nbsp;</span><span class="c3 c0">the same view angles and same levels of occlusions as what</span><span class="c0">&nbsp;</span><span class="c3 c0">we have been captured. In contrast, a dataset captured from high</span><span class="c0">&nbsp;</span><span class="c3 c0">above the ground would not include significant occlusions,</span><span class="c0">&nbsp;</span><span class="c3 c0">and any model trained on such a dataset would generalize</span><span class="c0">&nbsp;</span><span class="c3 c0">poorly to a low installation height (with strong occlusions</span><span class="c0">&nbsp;</span><span class="c3 c0 c6">between individual parking spaces).</span></p>
      <p class="c2"><span class="c4 c3"></span></p>
      <p class="c7"><span class="c4 c9">&nbsp;Annotation</span></p>
      <p class="c7"><span class="c3 c0">I labeled each image , using PolygoneZone </span><span class="c3 c0 c13 c20"><a class="c18" href="https://www.google.com/url?q=https://polygonzone.roboflow.com/&amp;sa=D&amp;source=editors&amp;ust=1752760924016048&amp;usg=AOvVaw2jV394bK_V0Qe-T1iKDMSJ">https://polygonzone.roboflow.com/</a></span><span class="c3 c0 c13">.</span><span class="c3 c0">&nbsp;To annotate one parking space,I drew a Polygon around it, ensuring that the edges of</span><span class="c0">&nbsp;</span><span class="c3 c0">the parking space and the Polygons are aligned. In a few</span><span class="c0">&nbsp;</span><span class="c3 c0">instances, however, when part of a parking space was cut</span><span class="c0">&nbsp;</span><span class="c3 c0">off at the edge of an image, the shape of the visible parking</span><span class="c0">&nbsp;</span><span class="c3 c0">space projection became a pentagon. For consistency, even</span><span class="c0">&nbsp;</span><span class="c3 c0">in these instances, we labeled such parking spaces using a</span><span class="c0">&nbsp;</span><span class="c3 c0">Polygon. This resulted in 2 of the 4 edges of the anno-rated Polygon not being aligned with the parking space.</span><span class="c0">&nbsp;</span><span class="c3 c0">This is visible on the bottom side of the colab.We only labeled those parking spaces where we were</span><span class="c0">&nbsp;</span><span class="c3 c0">confident about their coordinates and occupancy.</span></p>
      <p class="c2"><span class="c6 c3 c0"></span></p>
      <p class="c7"><span class="c6 c9 c0">Reference:</span></p>
      <p class="c7"><span class="c0">1.</span><span class="c8 c0">Kukartsev, V.V., Ageev, R.A., Borodulin, A.S., Gantimurov, A.P. and Kleshko, I.I., 2024, April. Deep learning for object detection in images development and evaluation of the yolov8 model using </span><span class="c0 c8">ultralytics</span><span class="c8 c0">&nbsp;and roboflow libraries. In </span><span class="c8 c0 c23">Computer Science On-line Conference</span><span class="c8 c0">&nbsp;(pp. 629-637). Cham: Springer Nature Switzerland.</span></p>
   </body>
</html>
